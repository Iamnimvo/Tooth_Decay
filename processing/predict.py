# processing/predict.py
# -*- coding: utf-8 -*-
"""
Predict + Grad-CAM with ROI gating.
Ø§ÙˆÙ„ÙˆÛŒØª ÙˆØ±ÙˆØ¯ÛŒ:
  1) Ø§Ú¯Ø± Ø¯Ø± ROOT/xray_pic/ Ø¹Ú©Ø³ Ù‡Ø³Øª â†’ Ù‡Ù…Ù‡ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù† (Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¹Ú©Ø³ ÛŒÚ© ÙÙˆÙ„Ø¯Ø± Ø®Ø±ÙˆØ¬ÛŒ)
  2) ÙˆÚ¯Ø±Ù†Ù‡ Ø§Ø² preprocess/preprocessed_images/ Ø­Ø¯Ø§Ú©Ø«Ø± 100 Ø¹Ú©Ø³ ØªØµØ§Ø¯ÙÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†.
Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± processing/predict_output/<image_stem>/ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯:
  - original.jpg
  - prediction_heatmap.jpg
  - prediction_circle.jpg        (Ø¯Ø§ÛŒØ±Ù‡ Ù‚Ø±Ù…Ø² + Ú©Ø§Ù†ØªÙˆØ± Ø³Ø¨Ø²)
  - prediction_gradcam.jpg       (overlay + Ø¯Ø§ÛŒØ±Ù‡/Ú©Ø§Ù†ØªÙˆØ±)
  - prediction_arrow.jpg
  - prediction_arrow_circle.jpg
"""

import os, cv2, torch, numpy as np, random
from torchvision import transforms
from ToothClassifier import ToothClassifier

# ===================== ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨ØµØ±ÛŒ/ØªØ­Ù„ÛŒÙ„ÛŒ =====================
CAM_POWER    = 2.0     # >1: ØªÛŒØ²ØªØ± Ú©Ø±Ø¯Ù† Ù†Ø§Ø­ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Øº Grad-CAM
THRESH_PCT   = 92      # Ø¢Ø³ØªØ§Ù†Ù‡ Ø¨Ù‡â€ŒØµÙˆØ±Øª ØµØ¯Ú© (Û¹Û°â€“Û¹Û¸ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯)
HEAT_ALPHA   = 0.35    # Ø´ÙØ§ÙÛŒØª Ù‡ÛŒØªâ€ŒÙ…Ù¾ Ø±ÙˆÛŒ ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ
MORPH_KERNEL = 5       # Ú©Ø±Ù†Ù„ Ø¹Ù…Ù„ÛŒØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆÚ˜ÛŒ
MIN_AREA     = 80      # Ø­Ø¯Ø§Ù‚Ù„ Ù…Ø³Ø§Ø­Øª Ú©Ø§Ù†ØªÙˆØ± ROI
MAX_BATCH    = 100     # Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ ØªØµÙˆÛŒØ± Ø§Ø² Ù¾ÙˆØ´Ù‡â€ŒÛŒ preprocess

# ===================== Ù…Ø³ÛŒØ±Ù‡Ø§ =====================
PROC_DIR     = os.path.dirname(__file__)                      # processing/
ROOT_DIR     = os.path.dirname(PROC_DIR)                      # Ø±ÛŒØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡
MODEL_PATH   = os.path.join(PROC_DIR, "tooth_classifier.pth")

XRAY_PICK_DIR = os.path.join(ROOT_DIR, "xray_pic")
PREP_IMG_DIR  = os.path.join(ROOT_DIR, "preprocess", "preprocessed_images")

OUT_ROOT    = os.path.join(PROC_DIR, "predict_output")
os.makedirs(OUT_ROOT, exist_ok=True)

# ===================== Ù…Ø¯Ù„ Ùˆ Ø¯ÛŒÙˆØ§ÛŒØ³ =====================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = ToothClassifier()
model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model.eval().to(device)

# ===================== ØªØ±Ù†Ø³ÙÙˆØ±Ù… ÙˆØ±ÙˆØ¯ÛŒ =====================
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485]*3, std=[0.229]*3),
])

# ===================== Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ =====================
IMG_EXTS = (".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff")

def list_images(d):
    if not os.path.isdir(d): return []
    return [os.path.join(d, f) for f in os.listdir(d) if f.lower().endswith(IMG_EXTS)]

def ensure_dir(p): os.makedirs(p, exist_ok=True)

def build_jaw_roi(gray: np.ndarray) -> np.ndarray:
    """
    Ø³Ø§Ø®Øª Ù…Ø§Ø³Ú© ROI Ø¨Ø±Ø§ÛŒ Ù†Ø§Ø­ÛŒÙ‡â€ŒÛŒ ÙÚ©/Ø¯Ù†Ø¯Ø§Ù† ØªØ§ Grad-CAM Ø¨ÛŒØ±ÙˆÙ† ÙÚ© Ø±Ø§ Ù†Ú¯ÛŒØ±Ø¯.
    Ø±ÙˆØ´: GaussianBlur + Otsu + morphology + Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒÙ† Ù…Ø¤Ù„ÙÙ‡â€ŒÛŒ Ù…ØªØµÙ„
    Ø®Ø±ÙˆØ¬ÛŒ: Ù…Ø§Ø³Ú© 0/255 Ù‡Ù…â€ŒØ§Ù†Ø¯Ø§Ø²Ù‡â€ŒÛŒ gray
    """
    blur = cv2.GaussianBlur(gray, (5,5), 0)
    # Ø¯Ù†Ø¯Ø§Ù†/ÙÚ© Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡â€ŒÛŒ Ø³ÛŒØ§Ù‡ Ø±ÙˆØ´Ù†â€ŒØªØ±Ù†Ø¯
    _, mask = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, k, iterations=2)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN,  k, iterations=1)
    cnts,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts: return mask
    c = max(cnts, key=cv2.contourArea)
    jaw = np.zeros_like(mask)
    cv2.drawContours(jaw, [c], -1, 255, -1)
    return jaw

def draw_arrow(img, target_pt, color=(0,0,255)):
    h, w = img.shape[:2]; cx, cy = target_pt
    start = (int(0.1*w), cy) if cx >= w//2 else (int(0.9*w), cy)
    cv2.arrowedLine(img, start, (cx, cy), color, 2, tipLength=0.03)

# ===================== Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© ØªØµÙˆÛŒØ± =====================
def process_one_image(img_path: str, out_dir: str):
    ensure_dir(out_dir)

    # --- Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø§ØµÙ„ ---
    orig = cv2.imread(img_path)
    if orig is None:
        print(f"âš ï¸ Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµÙˆÛŒØ± Ù†Ø§Ù…ÙˆÙÙ‚: {img_path}")
        return
    cv2.imwrite(os.path.join(out_dir, "original.jpg"), orig)

    # --- Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ù…Ø¯Ù„ ---
    gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)
    img3 = cv2.merge([gray, gray, gray])
    inp  = transform(img3).unsqueeze(0).to(device)

    # --- Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù„Ø§Ø³ ---
    with torch.no_grad():
        logits = model(inp)
    pred = logits.argmax(1).item()
    print("   â””â”€ Ù†ØªÛŒØ¬Ù‡:", "Ù¾ÙˆØ³ÛŒØ¯Ú¯ÛŒ" if pred == 1 else "Ø³Ø§Ù„Ù…")

    # --- HookÙ‡Ø§ÛŒ Grad-CAM Ø±ÙˆÛŒ Ø¢Ø®Ø±ÛŒÙ† Ù„Ø§ÛŒÙ‡ Ú©Ø§Ù†ÙˆÙ„ÙˆØ´Ù† ---
    target_layer = model.model.layer4[-1].conv2
    acts, grads = [], []
    def fwd_hook(m, i, o): acts.append(o.detach())
    def bwd_hook(m, gi, go): grads.append(go[0].detach())
    h1 = target_layer.register_forward_hook(fwd_hook)
    h2 = target_layer.register_full_backward_hook(bwd_hook)

    # --- Backward Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§Ø³ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡ ---
    model.zero_grad(set_to_none=True)
    score = model(inp)[0, pred]
    score.backward()

    # --- Ù…Ø­Ø§Ø³Ø¨Ù‡ CAM ---
    A = acts[0].squeeze(0).cpu().numpy()     # (C,H,W)
    G = grads[0].squeeze(0).cpu().numpy()    # (C,H,W)
    w = G.mean(axis=(1,2))                   # (C,)
    cam = np.maximum((w[:, None, None] * A).sum(0), 0)
    cam = cv2.resize(cam, (orig.shape[1], orig.shape[0]))
    cam -= cam.min()
    cam /= (cam.max() + 1e-6)
    cam = np.power(cam, CAM_POWER)

    # --- ROI gating: Ù…Ø­Ø¯ÙˆØ¯Ú©Ø±Ø¯Ù† CAM Ø¨Ù‡ ÙÚ©/Ø¯Ù†Ø¯Ø§Ù† ---
    roi_mask = build_jaw_roi(gray).astype(np.float32) / 255.0
    cam = cam * roi_mask

    # --- Threshold + Morphology ---
    thr  = np.percentile(cam[cam > 0], THRESH_PCT) if np.any(cam > 0) else 1.0
    mask = (cam >= thr).astype(np.uint8) * 255
    k    = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (MORPH_KERNEL, MORPH_KERNEL))
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, k, iterations=1)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN,  k, iterations=1)

    # --- ÛŒØ§ÙØªÙ† ROI (Ú©Ø§Ù†ØªÙˆØ± ÛŒØ§ fallback Ø¨Ù‡ Ø¨ÛŒØ´ÛŒÙ†Ù‡) ---
    circle_img = orig.copy()
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    center, r, best_cnt = None, None, None

    if cnts:
        cnts = [c for c in cnts if cv2.contourArea(c) >= MIN_AREA]
        if cnts:
            best_cnt = max(cnts, key=cv2.contourArea)
            (x, y), r = cv2.minEnclosingCircle(best_cnt)
            center, r = (int(x), int(y)), int(r)

    if center is None:
        # Ù†Ù‚Ø·Ù‡â€ŒÛŒ Ø¨ÛŒØ´ÛŒÙ†Ù‡ Ø¯Ø§Ø®Ù„ ROI
        valid = np.where(roi_mask > 0)
        if valid[0].size:
            # Ù…Ø®ØªØµØ§Øª Ù¾ÛŒÚ©Ø³Ù„ Ø¨ÛŒØ´ÛŒÙ†Ù‡â€ŒÛŒ CAM
            yy, xx = np.unravel_index(np.argmax(cam), cam.shape)
            center = (int(xx), int(yy))
        else:
            # Ø§Ú¯Ø± ROI Ù‡Ù… Ù†Ø¨ÙˆØ¯ØŒ ÙˆØ³Ø· ØªØµÙˆÛŒØ±
            h, w = cam.shape
            center = (w // 2, h // 2)
        r = max(int(0.05 * max(orig.shape[:2])), 12)

    # --- ØªØ±Ø³ÛŒÙ… Ø¯Ø§ÛŒØ±Ù‡/Ú©Ø§Ù†ØªÙˆØ± ---
    cv2.circle(circle_img, center, r, (0, 0, 255), 2)
    if best_cnt is not None:
        cv2.drawContours(circle_img, [best_cnt], -1, (0, 255, 0), 2)
    cv2.imwrite(os.path.join(out_dir, "prediction_circle.jpg"), circle_img)

    # --- Ù‡ÛŒØªâ€ŒÙ…Ù¾ Ùˆ Ù‡Ù…Ù¾ÙˆØ´Ø§Ù†ÛŒ ---
    heat = (cam * 255).astype(np.uint8)
    heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)
    overlay = cv2.addWeighted(orig, 1.0 - HEAT_ALPHA, heat, HEAT_ALPHA, 0)
    cv2.circle(overlay, center, r, (0, 0, 255), 2)
    if best_cnt is not None:
        cv2.drawContours(overlay, [best_cnt], -1, (0, 255, 0), 2)
    cv2.imwrite(os.path.join(out_dir, "prediction_heatmap.jpg"), heat)
    cv2.imwrite(os.path.join(out_dir, "prediction_gradcam.jpg"), overlay)

    # --- ÙÙ„Ø´â€ŒÙ‡Ø§ ---
    arrow = orig.copy()
    draw_arrow(arrow, center, (0,0,255))
    cv2.imwrite(os.path.join(out_dir, "prediction_arrow.jpg"), arrow)

    arrow_circle = circle_img.copy()
    draw_arrow(arrow_circle, center, (0,0,255))
    cv2.imwrite(os.path.join(out_dir, "prediction_arrow_circle.jpg"), arrow_circle)

    # --- Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† hook Ù‡Ø§ ---
    h1.remove(); h2.remove()

# ===================== Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ =====================
def main():
    # 1) Ø§Ú¯Ø± xray_pic/ Ø¹Ú©Ø³ Ø¯Ø§Ø±Ø¯ â†’ Ù‡Ù…Ù‡ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†
    pick_imgs = list_images(XRAY_PICK_DIR)
    if pick_imgs:
        print(f"ğŸ“‚ xray_pic: {len(pick_imgs)} ØªØµÙˆÛŒØ± Ù¾ÛŒØ¯Ø§ Ø´Ø¯.")
        for p in pick_imgs:
            stem = os.path.splitext(os.path.basename(p))[0]
            out_dir = os.path.join(OUT_ROOT, stem)
            print(f"â†’ Ù¾Ø±Ø¯Ø§Ø²Ø´: {p}")
            process_one_image(p, out_dir)
        print(f"âœ… ØªÙ…Ø§Ù… Ø´Ø¯. Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø¯Ø±: {OUT_ROOT}")
        return

    # 2) Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±Øª Ø§Ø² preprocessed_images Ø­Ø¯Ø§Ú©Ø«Ø± MAX_BATCH ØªØµÙˆÛŒØ± ØªØµØ§Ø¯ÙÛŒ
    all_pre = list_images(PREP_IMG_DIR)
    if not all_pre:
        raise FileNotFoundError("â›” Ù‡ÛŒÚ† ØªØµÙˆÛŒØ±ÛŒ Ø¯Ø± preprocess/preprocessed_images Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")

    k = min(MAX_BATCH, len(all_pre))
    batch = random.sample(all_pre, k)
    print(f"ğŸ“‚ preprocessed_images: {len(all_pre)} ØªØµÙˆÛŒØ± | Ø§Ù†ØªØ®Ø§Ø¨ ØªØµØ§Ø¯ÙÛŒ {k} Ø¹Ø¯Ø¯")

    for p in batch:
        stem = os.path.splitext(os.path.basename(p))[0]
        out_dir = os.path.join(OUT_ROOT, stem)
        print(f"â†’ Ù¾Ø±Ø¯Ø§Ø²Ø´: {p}")
        process_one_image(p, out_dir)

    print(f"âœ… ØªÙ…Ø§Ù… Ø´Ø¯. {k} ÙÙˆÙ„Ø¯Ø± Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø§Ø®Ù„: {OUT_ROOT}")

if __name__ == "__main__":
    main()
