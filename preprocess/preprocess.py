# -*- coding: utf-8 -*-
"""preprocess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f9kXpGXKmL2i1sn8Zn9oBZS0wvDknkrf
"""

import os
import cv2
import numpy as np
import boto3
import albumentations as A
from tqdm import tqdm

# ============================
# ğŸ” ØªÙ†Ø¸ÛŒÙ…Ø§Øª Arvan Ùˆ Ù…Ø³ÛŒØ±Ù‡Ø§
# ============================
access_key = "a8761df0-960e-4dd1-b5f2-ef8ef60823a9"
secret_key = "f502aad1cec94636d4381cadf302a6114df05bf825864e554b82010d6d2441ab"
region_name = "s3.ir-thr-at1.arvanstorage.ir"
bucket_name = "ehsannima"
folder_name = "xray/"

# Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¯Ø§Ø®Ù„ Ù¾ÙˆØ´Ù‡ preprocess
download_dir = "./preprocess/xray_images"  # ØªØºÛŒÛŒØ± Ù…Ø³ÛŒØ± Ø¨Ù‡ Ù¾ÙˆØ´Ù‡ preprocess
final_output_dir = "./preprocess/preprocessed_images"  # ØªØºÛŒÛŒØ± Ù…Ø³ÛŒØ± Ø¨Ù‡ Ù¾ÙˆØ´Ù‡ preprocess

# Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨Ø§Ø´Ù†Ø¯
os.makedirs(download_dir, exist_ok=True)
os.makedirs(final_output_dir, exist_ok=True)

# Ø§ØªØµØ§Ù„ Ø¨Ù‡ Arvan
s3 = boto3.client(
    "s3",
    endpoint_url=f"https://{region_name}",
    aws_access_key_id=access_key,
    aws_secret_access_key=secret_key,
)

# ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ±
print("ğŸ“¥ Downloading images from Arvan...")
response = s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_name)
for obj in response.get("Contents", []):
    key = obj["Key"]
    if key.endswith((".jpg", ".jpeg", ".png")):
        filename = os.path.basename(key)
        file_path = os.path.join(download_dir, filename)
        s3.download_file(bucket_name, key, file_path)

# ============================
# âš™ï¸ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ + Augmentation
# ============================
target_size = (224, 224)
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
num_augmented_per_image = 3

# Ø­Ø°Ù Ù†ÙˆØ§Ø­ÛŒ Ø³ÙÛŒØ¯
def contour_based_crop(img_gray):
    _, thresh = cv2.threshold(img_gray, 240, 255, cv2.THRESH_BINARY_INV)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return img_gray
    x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))
    return img_gray[y:y+h, x:x+w]

# resize ÛŒØ§ padding Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ² Ø«Ø§Ø¨Øª
def resize_or_pad(img, size=(224, 224)):
    h, w = img.shape
    target_h, target_w = size
    if h >= target_h and w >= target_w:
        return cv2.resize(img, size)
    delta_h = max(0, target_h - h)
    delta_w = max(0, target_w - w)
    top, bottom = delta_h // 2, delta_h - delta_h // 2
    left, right = delta_w // 2, delta_w - delta_w // 2
    return cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)

# âœ… ØªÙˆØ§Ù„ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ø¨Ø¯ÙˆÙ† Ù‡Ø´Ø¯Ø§Ø±
transform = A.Compose([
    A.RandomBrightnessContrast(p=0.5),
    A.HorizontalFlip(p=0.5),
    A.Rotate(limit=10, p=0.5),
    A.GaussianBlur(blur_limit=3, p=0.3),
    A.Affine(scale=(0.9, 1.1), translate_percent=0.05, p=0.5),
    A.ElasticTransform(alpha=1.0, sigma=50, alpha_affine=50, p=0.5),
    A.GridDistortion(distort_limit=0.3, p=0.3)
])

print("âš™ï¸ Starting preprocessing and augmentation...")

# ğŸ” Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±
for filename in tqdm(os.listdir(download_dir)):
    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):
        continue

    img_path = os.path.join(download_dir, filename)
    img = cv2.imread(img_path)
    if img is None:
        print(f"â›” ØªØµÙˆÛŒØ± Ø®Ø±Ø§Ø¨: {filename}")
        continue

    base_name = os.path.splitext(filename)[0]

    # Ù…Ø±Ø­Ù„Ù‡ 1: ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ grayscale
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Ù…Ø±Ø­Ù„Ù‡ 2: Ø­Ø°Ù Ù†ÙˆØ§Ø± Ø³ÙÛŒØ¯ + resize ÛŒØ§ padding
    img_cropped = contour_based_crop(img_gray)
    img_resized = resize_or_pad(img_cropped, size=target_size)

    # Ù…Ø±Ø­Ù„Ù‡ 3: Ø¨Ù‡Ø¨ÙˆØ¯ Ú©Ù†ØªØ±Ø§Ø³Øª Ùˆ Ø­Ø°Ù Ù†ÙˆÛŒØ²
    img_clahe = clahe.apply(img_resized)
    img_median_filtered = cv2.medianBlur(img_clahe, 5)  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙÛŒÙ„ØªØ± Ù…ÛŒØ§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù†ÙˆÛŒØ²
    img_bilateral_filtered = cv2.bilateralFilter(img_median_filtered, 9, 75, 75)  # ÙÛŒÙ„ØªØ± Ø¯Ùˆ Ø·Ø±ÙÙ‡ Ø¨Ø±Ø§ÛŒ Ø­ÙØ¸ Ù„Ø¨Ù‡â€ŒÙ‡Ø§

    # Ù…Ø±Ø­Ù„Ù‡ 4: Gaussian Blur Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ù†ÙˆÛŒØ² Ø¨ÛŒØ´ØªØ±
    img_final = cv2.GaussianBlur(img_bilateral_filtered, (3, 3), 0)

    # Ø°Ø®ÛŒØ±Ù‡ ØªØµÙˆÛŒØ± Ù†Ù‡Ø§ÛŒÛŒ
    cv2.imwrite(os.path.join(final_output_dir, f"{base_name}.jpg"), img_final)

    # Ù…Ø±Ø­Ù„Ù‡ 5: Ø³Ø§Ø®Øª ØªØµØ§ÙˆÛŒØ± Ø§ÙØ²ÙˆØ¯Ù‡
    for i in range(num_augmented_per_image):
        aug_img = transform(image=img_final)['image']
        aug_name = f"{base_name}_aug{i+1}.jpg"
        cv2.imwrite(os.path.join(final_output_dir, aug_name), aug_img)

print(f"\nâœ… Ù‡Ù…Ù‡ ØªØµØ§ÙˆÛŒØ± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø¯Ø± {final_output_dir} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")